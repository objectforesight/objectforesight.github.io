<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ObjectForesight: Predicting Future 3D Object Trajectories from Human Videos</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans:ital,wght@0,300;0,400;0,500;0,600;0,700;1,400&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        :root {
            --primary-color: #222;
            --secondary-color: #444;
            --accent-color: #4a90d9;
            --venue-color: #e53935;
            --caption-bg: #e8d4f8;
            --light-bg: #f7f8f9;
            --border-radius: 6px;
            --max-width: 950px;
            --content-width: 880px;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            font-size: 15px;
            -webkit-font-smoothing: antialiased;
            -moz-osx-font-smoothing: grayscale;
        }

        body {
            font-family: 'Noto Sans', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.65;
            color: var(--primary-color);
            background-color: #fff;
            font-weight: 400;
        }

        .container {
            max-width: var(--max-width);
            margin: 0 auto;
            padding: 0 20px;
        }

        /* Header Section */
        .header {
            text-align: center;
            padding: 25px 20px 40px;
        }

        .logo {
            width: 300px;
            height: auto;
            margin-bottom: 5px;
        }

        .title {
            font-size: 3.2rem;
            font-weight: 600;
            color: var(--primary-color);
            margin-bottom: 12px;
            letter-spacing: -0.5px;
        }

        .subtitle {
            font-size: 1.7rem;
            font-weight: 400;
            color: var(--primary-color);
            margin-bottom: 20px;
            line-height: 1.4;
        }

        .venue {
            font-size: 1.15rem;
            color: var(--venue-color);
            font-weight: 600;
            margin-bottom: 20px;
        }

        .authors {
            margin-bottom: 8px;
            line-height: 1.8;
        }

        .authors a {
            color: var(--accent-color);
            text-decoration: none;
            font-size: 1.2rem;
            font-weight: 400;
        }

        .authors a:hover {
            text-decoration: underline;
        }

        .authors sup {
            font-size: 0.65rem;
            margin-left: 1px;
            color: var(--accent-color);
        }

        .affiliations {
            font-size: 1.1rem;
            color: var(--secondary-color);
            margin-bottom: 5px;
        }

        .affiliations sup {
            font-size: 0.65rem;
        }

        .equal-advising {
            font-size: 0.9rem;
            color: #666;
            margin-bottom: 24px;
        }

        /* Buttons */
        .buttons {
            display: flex;
            justify-content: center;
            gap: 10px;
            flex-wrap: wrap;
        }

        .btn {
            display: inline-flex;
            align-items: center;
            gap: 6px;
            padding: 8px 18px;
            background-color: #363636;
            color: #fff;
            text-decoration: none;
            border-radius: 18px;
            font-size: 0.9rem;
            font-weight: 500;
            transition: all 0.2s ease;
        }

        .btn:hover {
            background-color: #505050;
        }

        .btn-disabled {
            background-color: #999;
            pointer-events: none;
            cursor: not-allowed;
        }

        .btn i {
            font-size: 0.95rem;
        }

        /* Teaser Section */
        .teaser {
            text-align: center;
            padding: 30px 0 0;
        }

        .teaser-text {
            font-size: 1rem;
            max-width: var(--content-width);
            margin: 0 auto 28px;
            text-align: center;
            line-height: 1.75;
            color: var(--secondary-color);
        }

        .teaser-text strong {
            font-weight: 600;
            color: var(--primary-color);
        }

        .teaser-video {
            max-width: 850px;
            margin: 0 auto 28px;
        }

        .teaser-video video,
        .teaser-video img {
            width: 100%;
            border-radius: var(--border-radius);
            box-shadow: 0 2px 12px rgba(0,0,0,0.1);
        }

        /* Abstract Section */
        .abstract {
            padding: 10px 0 10px;
        }

        .abstract p {
            max-width: var(--content-width);
            margin: 0 auto;
            font-size: 0.95rem;
            line-height: 1.8;
            text-align: justify;
            color: var(--secondary-color);
        }

        /* Section Headers */
        .section-header {
            text-align: center;
            font-size: 1.6rem;
            font-weight: 500;
            margin: 18px 0 12px;
            color: var(--primary-color);
        }

        /* Architecture Section */
        .architecture {
            padding: 0 0 10px;
        }

        .architecture-description {
            max-width: var(--content-width);
            margin: 0 auto 20px;
            text-align: justify;
            font-size: 0.95rem;
            line-height: 1.75;
            color: var(--secondary-color);
        }

        .architecture-points {
            max-width: var(--content-width);
            margin: 0 auto 30px;
            padding-left: 20px;
            list-style-type: disc;
        }

        .architecture-points li {
            margin-bottom: 10px;
            line-height: 1.7;
            color: var(--secondary-color);
            font-size: 0.95rem;
        }

        .architecture-points li strong {
            color: var(--primary-color);
            font-weight: 600;
        }

        .architecture-figure {
            max-width: 780px;
            margin: 0 auto;
            text-align: center;
        }

        .architecture-figure img,
        .architecture-figure video {
            max-width: 100%;
            border-radius: var(--border-radius);
            box-shadow: 0 2px 12px rgba(0,0,0,0.1);
        }

        .figure-caption {
            font-size: 0.82rem;
            color: #666;
            margin-top: 10px;
            font-style: italic;
        }

        /* Data Curation Section */
        .data-curation {
            padding: 0 0 10px;
        }

        .data-curation-description {
            max-width: var(--content-width);
            margin: 0 auto 25px;
            text-align: justify;
            font-size: 0.95rem;
            line-height: 1.75;
            color: var(--secondary-color);
        }

        .pipeline-figure {
            max-width: 850px;
            margin: 0 auto;
            text-align: center;
        }

        .pipeline-figure img,
        .pipeline-figure video {
            max-width: 100%;
            border-radius: var(--border-radius);
            box-shadow: 0 2px 12px rgba(0,0,0,0.1);
        }

        /* Demo Videos Section */
        .demos {
            padding: 15px 0 40px;
            background-color: var(--light-bg);
        }

        .demos .container {
            max-width: 1050px;
        }

        .demos-description {
            max-width: var(--content-width);
            margin: 0 auto 25px;
            text-align: center;
            font-size: 0.95rem;
            line-height: 1.75;
            color: var(--secondary-color);
        }

        .demo-category {
            margin-bottom: 30px;
        }

        .demo-category:last-child {
            margin-bottom: 0;
        }

        .demo-category-title {
            font-size: 1.05rem;
            font-weight: 500;
            margin-bottom: 12px;
            color: var(--primary-color);
        }

        .demo-grid {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 18px;
        }

        /* Tablet breakpoint */
        @media (max-width: 900px) {
            .title {
                font-size: 2.6rem;
            }

            .subtitle {
                font-size: 1.4rem;
            }

            .authors a {
                font-size: 1.1rem;
            }

            .affiliations {
                font-size: 1rem;
            }

            .comparison-labels {
                grid-template-columns: 2fr 10px 1fr;
            }

            .comparison-grid {
                grid-template-columns: 2fr 10px 1fr;
            }
        }

        /* Small tablet breakpoint */
        @media (max-width: 768px) {
            .title {
                font-size: 2.2rem;
            }

            .subtitle {
                font-size: 1.2rem;
            }

            .demo-grid {
                grid-template-columns: 1fr;
                gap: 15px;
            }

            .section-header {
                font-size: 1.45rem;
            }
        }

        /* Mobile breakpoint */
        @media (max-width: 600px) {
            .header {
                padding: 20px 15px 30px;
            }

            .logo {
                width: 220px;
                margin-bottom: 4px;
            }

            .title {
                font-size: 1.8rem;
            }

            .subtitle {
                font-size: 1.05rem;
            }

            .authors a {
                font-size: 1rem;
            }

            .affiliations {
                font-size: 0.95rem;
            }

            .venue {
                font-size: 1rem;
            }

            .btn {
                padding: 10px 18px;
                font-size: 0.9rem;
            }

            .section-header {
                font-size: 1.35rem;
            }

            .teaser-text,
            .abstract p,
            .architecture-description,
            .architecture-points li,
            .data-curation-description,
            .demos-description,
            .acknowledgements p {
                text-align: left;
            }

            .demo-grid {
                grid-template-columns: 1fr;
            }

            .demo-tabs {
                flex-wrap: wrap;
            }

            .demo-tab {
                padding: 10px 18px;
            }

            .pagination-btn {
                width: 40px;
                height: 40px;
                font-size: 0.9rem;
            }

            .comparison-labels {
                grid-template-columns: 1fr;
                gap: 0;
            }

            .comparison-labels span:nth-child(2) {
                display: none;
            }

            .comparison-grid {
                grid-template-columns: 1fr;
                gap: 10px;
            }

            .comparison-grid .spacer {
                display: none;
            }

            .comparison-row {
                margin-bottom: 25px;
            }

            .comparison-header {
                font-size: 0.9rem;
                padding: 14px 16px;
            }

            .bibtex-block {
                padding: 14px 16px;
                font-size: 0.7rem;
            }

            .container {
                padding: 0 15px;
            }
        }

        .demo-item {
            background: #fff;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 10px rgba(0,0,0,0.07);
            transition: transform 0.2s ease, box-shadow 0.2s ease;
        }

        .demo-item:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 16px rgba(0,0,0,0.1);
        }

        .demo-item video {
            width: 100%;
            display: block;
        }

        .demo-caption {
            background: var(--caption-bg);
            padding: 12px 12px;
            text-align: center;
            font-size: 0.85rem;
            color: var(--secondary-color);
            min-height: 60px;
            display: flex;
            align-items: center;
            justify-content: center;
            line-height: 1.45;
        }

        /* Acknowledgements */
        .acknowledgements {
            padding: 35px 0;
        }

        .acknowledgements p {
            max-width: var(--content-width);
            margin: 0 auto;
            text-align: justify;
            line-height: 1.75;
            font-size: 0.95rem;
            color: var(--secondary-color);
        }

        /* BibTeX */
        .bibtex {
            padding: 20px 0 50px;
        }

        .bibtex-block {
            max-width: var(--content-width);
            margin: 0 auto;
            background: #f5f5f5;
            border-radius: var(--border-radius);
            padding: 18px 22px;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
            font-size: 0.8rem;
            line-height: 1.6;
            overflow-x: auto;
            color: var(--secondary-color);
            border: 1px solid #e8e8e8;
        }

        .bibtex-block pre {
            margin: 0;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        /* Footer */
        .footer {
            text-align: center;
            padding: 25px 20px;
            background: #f0f0f0;
            font-size: 0.85rem;
            color: #666;
            border-top: 1px solid #e0e0e0;
        }

        .footer a {
            color: var(--accent-color);
            text-decoration: none;
        }

        .footer a:hover {
            text-decoration: underline;
        }

        /* Video placeholder styling */
        .video-placeholder {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            width: 100%;
            aspect-ratio: 16/9;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-size: 1rem;
            border-radius: var(--border-radius);
            box-shadow: 0 2px 12px rgba(0,0,0,0.08);
        }

        .video-placeholder i {
            font-size: 2rem;
            margin-bottom: 10px;
            opacity: 0.9;
        }

        .video-placeholder-content {
            text-align: center;
        }

        .video-placeholder small {
            opacity: 0.8;
            font-size: 0.8rem;
        }

        /* Smooth scrolling */
        html {
            scroll-behavior: smooth;
        }

        /* Selection color */
        ::selection {
            background: rgba(93, 173, 226, 0.3);
        }

        /* Pagination styles */
        .demo-tabs {
            display: flex;
            justify-content: center;
            gap: 8px;
            margin-bottom: 25px;
        }

        .demo-tab {
            padding: 8px 20px;
            background: #fff;
            border: 2px solid #ddd;
            border-radius: 20px;
            cursor: pointer;
            font-size: 0.9rem;
            font-weight: 500;
            color: var(--secondary-color);
            transition: all 0.2s ease;
        }

        .demo-tab:hover {
            border-color: var(--accent-color);
            color: var(--accent-color);
        }

        .demo-tab.active {
            background: var(--accent-color);
            border-color: var(--accent-color);
            color: #fff;
        }

        .demo-page {
            display: none;
        }

        .demo-page.active {
            display: block;
        }

        .pagination {
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 8px;
            margin-top: 20px;
        }

        .pagination-btn {
            width: 32px;
            height: 32px;
            border-radius: 50%;
            border: 2px solid #ddd;
            background: #fff;
            cursor: pointer;
            font-size: 0.85rem;
            font-weight: 500;
            color: var(--secondary-color);
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .pagination-btn:hover {
            border-color: var(--accent-color);
            color: var(--accent-color);
        }

        .pagination-btn.active {
            background: var(--accent-color);
            border-color: var(--accent-color);
            color: #fff;
        }

        .pagination-btn:disabled {
            opacity: 0.4;
            cursor: not-allowed;
        }

        /* Comparison collapsible section */
        .comparison-section {
            margin-top: 30px;
        }

        .comparison-header {
            display: flex;
            align-items: center;
            gap: 8px;
            cursor: pointer;
            padding: 12px 16px;
            background: #fff;
            border: 2px solid #ddd;
            border-radius: 8px;
            font-size: 1rem;
            font-weight: 500;
            color: var(--secondary-color);
            transition: all 0.2s ease;
        }

        .comparison-header:hover {
            border-color: var(--accent-color);
            color: var(--accent-color);
        }

        .comparison-header .arrow {
            transition: transform 0.2s ease;
        }

        .comparison-header.expanded .arrow {
            transform: rotate(90deg);
        }

        .comparison-content {
            display: none;
            margin-top: 20px;
        }

        .comparison-content.show {
            display: block;
        }

        .comparison-row {
            margin-bottom: 20px;
        }

        .comparison-row:last-child {
            margin-bottom: 0;
        }

        .comparison-labels {
            display: grid;
            grid-template-columns: 3fr 10px 1fr;
            gap: 4px;
            margin-bottom: 8px;
            text-align: center;
            font-size: 0.85rem;
            font-weight: 500;
            color: var(--secondary-color);
        }

        .comparison-grid {
            display: grid;
            grid-template-columns: 3fr 10px 1fr;
            gap: 4px;
            align-items: start;
        }

        .comparison-grid .spacer {
            width: 10px;
        }

        .comparison-grid video {
            width: 100%;
            border-radius: 6px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.08);
        }
    </style>
</head>
<body>

    <!-- Header -->
    <header class="header">
        <img src="logo.png" alt="ObjectForesight Logo" class="logo">
        <h1 class="title">ObjectForesight</h1>
        <h2 class="subtitle">Predicting Future 3D Object Trajectories from Human Videos</h2>

        <div class="authors">
            <a href="mailto:rustin@cs.washington.edu">Rustin Soraki</a><sup>1</sup>,
            <a href="#">Homanga Bharadhwaj</a><sup>2*</sup>,
            <a href="#">Ali Farhadi</a><sup>1*</sup>,
            <a href="#">Roozbeh Mottaghi</a><sup>1*</sup>
        </div>
        <p class="affiliations"><sup>1</sup>University of Washington, <sup>2</sup>Carnegie Mellon University</p>
        <p class="equal-advising"><sup>*</sup>Equal Supervision</p>

        <div class="buttons">
            <a href="paper.pdf" class="btn"><i class="fas fa-file-pdf"></i> Paper</a>
            <a href="http://arxiv.org/abs/2601.05237" class="btn"><i class="fas fa-archive"></i> arXiv</a>
            <a href="#" class="btn btn-disabled"><i class="fab fa-github"></i> Code (coming soon)</a>
            <a href="#" class="btn btn-disabled"><i class="fas fa-database"></i> Data (coming soon)</a>
        </div>
    </header>

    <!-- Teaser -->
    <section class="teaser">
        <div class="container">
            <p class="teaser-text">
                We introduce <strong>ObjectForesight</strong>, a framework for predicting future <strong>6-DoF</strong> object trajectories
                from a short history of egocentric observations. We train the model on just generic human videos of interactions without any task/skill-specific separation, and demonstrate generalization to diverse plausible manipulations of objects in new scenes.
                </p>

            <div class="teaser-video">
                <video autoplay muted loop playsinline>
                    <source src="videos/teaser_web.mp4" type="video/mp4">
                </video>
            </div>

            <p class="teaser-text">
                Our contributions are:
                (1) formalizing 3D object dynamics prediction from human videos, (2) a geometry-aware, object-centric diffusion model for 6-DoF
                trajectory prediction, and (3) a large-scale dataset of <strong>2 million+</strong> object-centric 3D trajectories with pseudo-ground-truth.
            </p>
        </div>
    </section>

    <!-- Abstract -->
    <section class="abstract">
        <div class="container">
            <h2 class="section-header">Abstract</h2>
            <p>
                Humans can effortlessly anticipate how objects might move or change through interaction—imagining a cup being lifted, a knife slicing, or a lid being closed. We aim to endow computational systems with a similar ability to predict plausible future object motions directly from passive visual observation. We introduce ObjectForesight, a 3D object-centric dynamics model that predicts future 6-DoF poses and trajectories of rigid objects from short egocentric video sequences. Unlike conventional world/dynamics models that operate in pixel or latent space, ObjectForesight represents the world explicitly in 3D at the object level, enabling geometrically grounded and temporally coherent predictions that capture object affordances and trajectories. To train such a model at scale, we leverage recent advances in segmentation, mesh reconstruction, and 3D pose estimation to curate a dataset of 2 million+ short clips with pseudo-ground-truth 3D object trajectories. Through extensive experiments, we show that ObjectForesight achieves significant gains in accuracy, geometric consistency, and generalization to unseen objects and scenes—establishing a scalable framework for learning physically grounded, object-centric dynamics models directly from observation.
            </p>

        </div>
    </section>

    <!-- Architecture Section -->
    <section class="architecture">
        <div class="container">
          <h2 class="section-header">Model Architecture</h2>
    
          <p class="architecture-description">
            ObjectForesight combines a geometry-aware 3D point encoder (PointTransformerV3) with a Diffusion Transformer (DiT) to forecast future object motion. From an anchor-frame point cloud, a short pose history with normalized boxes, and the
      object mask, we build a scene embedding and predict a <strong>multi-modal</strong> distribution over future 6-DoF pose sequences via denoising diffusion.
          </p>
    
          <ul class="architecture-points">
            <li><strong>Geometry + Context:</strong> A PointTransformerV3 encoder conditions point features on motion context (FiLM) and produces an object-centric scene embedding.</li>
            <li><strong>Stable Tokens:</strong> We predict depth-normalized 9D pose tokens for improved numerical stability.</li>
            <li><strong>Diffusion Forecasting:</strong> A DiT with AdaLN-Zero conditioning denoises future tokens using v-parameterization and p2 weighting; DDIM sampling yields smooth, diverse trajectories.</li>
          </ul>
    
          <div class="architecture-figure">
            <video autoplay muted loop playsinline>
              <source src="videos/architecture_web.mp4" type="video/mp4">
            </video>
            <p class="figure-caption">
              Model architecture: conditioned on anchor-frame geometry and past poses, ObjectForesight predicts future 6-DoF object trajectories.
            </p>
          </div>
        </div>
      </section>

    <!-- Data Curation Section -->
    <section class="data-curation">
        <div class="container">
          <h2 class="section-header">Data Curation</h2>
    
          <p class="data-curation-description">
            We curate large-scale 6-DoF object trajectories from in-the-wild egocentric video using an automated pipeline with quality gates. Starting from action segments, we detect hands and candidate manipulated objects (EgoHOS), refine and
      track masks over time (SAM2), and filter for clear manipulations and good viewpoints. We reconstruct object geometry (TRELLIS), recover metric depth and camera motion (SpaTrackerV2), and track 6-DoF poses with FoundationPose using
      bidirectional tracking and re-registration. This yields <strong>2 million+</strong> short, metrically grounded, temporally coherent object-centric trajectories.
          </p>
    
          <div class="pipeline-figure">
            <video autoplay muted loop playsinline>
              <source src="videos/datacuration_web.mp4" type="video/mp4">
            </video>
            <p class="figure-caption">
              Data curation pipeline: from egocentric video to 3D object trajectories using EgoHOS, SAM2, TRELLIS, SpaTrackerV2, and FoundationPose.
            </p>
          </div>
        </div>
      </section>

    <!-- Demo Videos Section -->
    <section class="demos">
        <div class="container">
            <h2 class="section-header">Qualitative Results</h2>
            <p class="demos-description">
                We show qualitative results of ObjectForesight on unseen clips in HOT3D and EpicKitchens. We can see that the future 3D predictions are plausible and correspond meaningfully to manipulations of the object given the context frames as condition.
            </p>

            <!-- Dataset Tabs -->
            <div class="demo-tabs">
                <button class="demo-tab active" data-dataset="hot3d">HOT3D</button>
                <button class="demo-tab" data-dataset="epic">EpicKitchen</button>
            </div>

            <!-- EpicKitchen Page (1 page, 6 videos) -->
            <div class="demo-page" data-dataset="epic" data-page="1">
                <div class="demo-grid">
                    <div class="demo-item">
                        <video controls muted loop>
                            <source src="videos/epickitchen/epic1.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="demo-item">
                        <video controls muted loop>
                            <source src="videos/epickitchen/epic2.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="demo-item">
                        <video controls muted loop>
                            <source src="videos/epickitchen/epic3.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="demo-item">
                        <video controls muted loop>
                            <source src="videos/epickitchen/epic4.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="demo-item">
                        <video controls muted loop>
                            <source src="videos/epickitchen/epic5.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="demo-item">
                        <video controls muted loop>
                            <source src="videos/epickitchen/epic6.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
            </div>

            <!-- HOT3D Page 1 (6 videos) -->
            <div class="demo-page active" data-dataset="hot3d" data-page="1">
                <div class="demo-grid">
                    <div class="demo-item">
                        <video controls muted loop>
                            <source src="videos/hot3d/hot3d1.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="demo-item">
                        <video controls muted loop>
                            <source src="videos/hot3d/hot3d2.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="demo-item">
                        <video controls muted loop>
                            <source src="videos/hot3d/hot3d3.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="demo-item">
                        <video controls muted loop>
                            <source src="videos/hot3d/hot3d4.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="demo-item">
                        <video controls muted loop>
                            <source src="videos/hot3d/hot3d5.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="demo-item">
                        <video controls muted loop>
                            <source src="videos/hot3d/hot3d6.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
                <div class="pagination" data-dataset="hot3d">
                    <button class="pagination-btn active" data-page="1">1</button>
                    <button class="pagination-btn" data-page="2">2</button>
                </div>
            </div>

            <!-- HOT3D Page 2 (6 videos) -->
            <div class="demo-page" data-dataset="hot3d" data-page="2">
                <div class="demo-grid">
                    <div class="demo-item">
                        <video controls muted loop>
                            <source src="videos/hot3d/hot3d7.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="demo-item">
                        <video controls muted loop>
                            <source src="videos/hot3d/hot3d8.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="demo-item">
                        <video controls muted loop>
                            <source src="videos/hot3d/hot3d9.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="demo-item">
                        <video controls muted loop>
                            <source src="videos/hot3d/hot3d10.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="demo-item">
                        <video controls muted loop>
                            <source src="videos/hot3d/hot3d11.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="demo-item">
                        <video controls muted loop>
                            <source src="videos/hot3d/hot3d12.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
                <div class="pagination" data-dataset="hot3d">
                    <button class="pagination-btn" data-page="1">1</button>
                    <button class="pagination-btn active" data-page="2">2</button>
                </div>
            </div>

            <!-- Comparison Section -->
            <div class="comparison-section">
                <div class="comparison-header">
                    <i class="fas fa-chevron-right arrow"></i>
                    <span>Comparison with video generation model</span>
                </div>
                <div class="comparison-content">
                    <div class="comparison-labels">
                        <span>GT | Luma AI | Ours</span>
                        <span></span>
                        <span>Luma Output</span>
                    </div>

                    <!-- Row 1 -->
                    <div class="comparison-row">
                        <div class="comparison-grid">
                            <video controls muted loop>
                                <source src="videos/comparison/row1_compare.mp4" type="video/mp4">
                            </video>
                            <div class="spacer"></div>
                            <video controls muted loop>
                                <source src="videos/comparison/row1_context.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>

                    <!-- Row 2 -->
                    <div class="comparison-row">
                        <div class="comparison-grid">
                            <video controls muted loop>
                                <source src="videos/comparison/row2_compare.mp4" type="video/mp4">
                            </video>
                            <div class="spacer"></div>
                            <video controls muted loop>
                                <source src="videos/comparison/row2_context.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>

                    <!-- Row 3 -->
                    <div class="comparison-row">
                        <div class="comparison-grid">
                            <video controls muted loop>
                                <source src="videos/comparison/row3_compare.mp4" type="video/mp4">
                            </video>
                            <div class="spacer"></div>
                            <video controls muted loop>
                                <source src="videos/comparison/row3_context.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Acknowledgements -->
    <section class="acknowledgements">
        <div class="container">
            <h2 class="section-header">Acknowledgements</h2>
            <p>
                We thank our colleagues at the University of Washington and Carnegie Mellon University for helpful discussions throughout this project.
            </p>
        </div>
    </section>

    <!-- BibTeX -->
    <section class="bibtex">
        <div class="container">
            <h2 class="section-header">BibTeX</h2>
            <div class="bibtex-block"><pre>@misc{soraki2026objectforesightpredictingfuture3d,
  title={ObjectForesight: Predicting Future 3D Object Trajectories from Human Videos},
  author={Rustin Soraki and Homanga Bharadhwaj and Ali Farhadi and Roozbeh Mottaghi},
  year={2026},
  eprint={2601.05237},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2601.05237}
}</pre></div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
        <p>Website template inspired by <a href="https://www.chenbao.tech/handsonvlm/">HandsOnVLM</a> and <a href="https://nerfies.github.io/">Nerfies</a>.</p>
    </footer>

    <script>
        // Dataset tab switching
        document.querySelectorAll('.demo-tab').forEach(tab => {
            tab.addEventListener('click', () => {
                const dataset = tab.dataset.dataset;

                // Update active tab
                document.querySelectorAll('.demo-tab').forEach(t => t.classList.remove('active'));
                tab.classList.add('active');

                // Hide all pages, show first page of selected dataset
                document.querySelectorAll('.demo-page').forEach(page => {
                    page.classList.remove('active');
                });
                const firstPage = document.querySelector(`.demo-page[data-dataset="${dataset}"][data-page="1"]`);
                if (firstPage) firstPage.classList.add('active');

                // Pause all videos
                document.querySelectorAll('.demo-page video').forEach(v => v.pause());
            });
        });

        // Pagination
        document.querySelectorAll('.pagination-btn').forEach(btn => {
            btn.addEventListener('click', () => {
                const page = btn.dataset.page;
                const pagination = btn.closest('.pagination');
                const dataset = pagination.dataset.dataset;

                // Hide all pages of this dataset
                document.querySelectorAll(`.demo-page[data-dataset="${dataset}"]`).forEach(p => {
                    p.classList.remove('active');
                });

                // Show selected page
                const targetPage = document.querySelector(`.demo-page[data-dataset="${dataset}"][data-page="${page}"]`);
                if (targetPage) targetPage.classList.add('active');

                // Update pagination buttons on all pages of this dataset
                document.querySelectorAll(`.pagination[data-dataset="${dataset}"] .pagination-btn`).forEach(b => {
                    b.classList.toggle('active', b.dataset.page === page);
                });

                // Pause all videos
                document.querySelectorAll('.demo-page video').forEach(v => v.pause());
            });
        });

        // Comparison section toggle
        document.querySelector('.comparison-header')?.addEventListener('click', function() {
            this.classList.toggle('expanded');
            document.querySelector('.comparison-content').classList.toggle('show');
            // Pause videos when collapsed
            if (!this.classList.contains('expanded')) {
                document.querySelectorAll('.comparison-content video').forEach(v => v.pause());
            }
        });
    </script>
</body>
</html>
